{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62db2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd64d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df = pd.DataFrame(pd.read_csv(r'C:\\Users\\ibrah\\OneDrive\\Desktop\\Intro to ML\\HW4\\Housing.csv'))\n",
    "features = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "df = df[features]\n",
    "df = StandardScaler().fit_transform(df) \n",
    "\n",
    "Y = df[:, 0]\n",
    "X = df[:, 1:6]\n",
    "\n",
    "t_Y = torch.tensor(Y)\n",
    "t_X = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51098046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and validation\n",
    "n_samples = t_X.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_X_train = t_X[train_indices]\n",
    "t_Y_train = t_Y[train_indices]\n",
    "\n",
    "t_X_val = t_X[val_indices]\n",
    "t_Y_val = t_Y[val_indices]\n",
    "\n",
    "t_Xn_train = 0.1 * t_X_train\n",
    "t_Xn_val = 0.1 * t_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b45a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define models\n",
    "linear_model = nn.Linear(1 , 1)\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2585b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 1))\n",
    "seq_model = seq_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e92954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_X_train, t_X_val,\n",
    "                  t_Y_train, t_Y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_X_train) # <1>\n",
    "        loss_train = loss_fn(t_p_train, t_Y_train)\n",
    "\n",
    "        t_p_val = model(t_X_val) # <1>\n",
    "        loss_val = loss_fn(t_p_val, t_Y_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f68c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0798, Validation loss 0.7032\n",
      "Epoch 50, Training loss 1.0792, Validation loss 0.7004\n",
      "Epoch 100, Training loss 1.0787, Validation loss 0.6982\n",
      "Epoch 150, Training loss 1.0785, Validation loss 0.6966\n",
      "Epoch 200, Training loss 1.0783, Validation loss 0.6954\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_X_train = t_Xn_train,\n",
    "    t_X_val = t_Xn_val, \n",
    "    t_Y_train = t_Y_train,\n",
    "    t_Y_val = t_Y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4044a3e",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e2468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefine models for part b\n",
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(5, 8), # <1>\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8, 16), # <2>\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(16, 32), # <3>\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 1))\n",
    "\n",
    "seq_model = seq_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069db9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0798, Validation loss 0.7032\n",
      "Epoch 50, Training loss 1.0798, Validation loss 0.7032\n",
      "Epoch 100, Training loss 1.0798, Validation loss 0.7032\n",
      "Epoch 150, Training loss 1.0798, Validation loss 0.7032\n",
      "Epoch 200, Training loss 1.0798, Validation loss 0.7032\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_X_train = t_Xn_train,\n",
    "    t_X_val = t_Xn_val, \n",
    "    t_Y_train = t_Y_train,\n",
    "    t_Y_val = t_Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50ac53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
